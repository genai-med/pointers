<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN" "http://www.w3.org/TR/html4/strict.dtd">
<html><head><meta content="text/html; charset=ISO-8859-1" http-equiv="content-type"><title>Generative AI in medicine and health/care: handpicked news, posts and articles from around the Web</title></head><body>
<h1>Generative AI in medicine and health/care: handpicked news, posts and articles from around the Web</h1>
<a href="#Jul24">July 2024</a><br>
<a href="#Aug24">August 2024</a><br>
<a href="#Sep24">Setpember 2024</a><br>
<br>
<h2><a name="Jul24"></a>July 2024 </h2>
<span style="font-weight: bold;">AI is complicating plagiarism. How should scientists respond?</span><br>
The explosive uptake of generative artificial intelligence in writing
is raising difficult questions about when use of the technology should
be allowed<br>
<a href="https://www.nature.com/articles/d41586-024-02371-z" target="_blank">https://www.nature.com/articles/d41586-024-02371-z</a><br>
<br>
<span style="font-weight: bold;">Clinician attitudes toward AI</span><br>
In the latest of Elsevier's annual reports looking at the future of
healthcare, clinicians have growing optimism about the capability of AI
to increase their productivity, freeing up their time for high value
work. However, this is accompanied by caution about AI's impact on
critical thinking and clinical decision making<br>
<a href="https://www.elsevier.com/en-gb/insights/attitudes-toward-ai#2-focus-on-clinicians" target="_blank">https://www.elsevier.com/en-gb/insights/attitudes-toward-ai#2-focus-on-clinicians</a><br>
<br>
<span style="font-weight: bold;">Academic authors 'shocked' after Taylor &amp; Francis sells access to their research to Microsoft AI</span><br>
<a href="https://www.thebookseller.com/news/academic-authors-shocked-after-taylor--francis-sells-access-to-their-research-to-microsoft-ai" target="_blank">https://www.thebookseller.com/news/academic-authors-shocked-after-taylor--francis-sells-access-to-their-research-to-microsoft-ai</a><br>
<br>
<span style="font-weight: bold;">Generative artificial intelligence, patient safety and healthcare quality: a review</span><br>
<a href="https://qualitysafety.bmj.com/content/early/2024/07/24/bmjqs-2023-016690" target="_blank">https://qualitysafety.bmj.com/content/early/2024/07/24/bmjqs-2023-016690</a><br>
<h2><a name="Aug24"></a>August 2024</h2>
<span style="font-weight: bold;">Has your paper been used to train an AI model? Almost certainly</span><br>
Artificial-intelligence developers are buying access to valuable data
sets that contain research papers &#8212; raising uncomfortable questions
about copyright<br>
<a href="https://www.nature.com/articles/d41586-024-02599-9" target="_blank">https://www.nature.com/articles/d41586-024-02599-9</a><br>
<br>
<span style="font-weight: bold;">Authors sue Anthropic for training AI using pirated books</span><br>
The authors accuse Anthropic of copyright infringement for training its
AI models on the Books3 dataset, which contains pirated ebooks<br>
<a href="https://www.theverge.com/2024/8/20/24224450/anthropic-copyright-lawsuit-pirated-books-ai" target="_blank">https://www.theverge.com/2024/8/20/24224450/anthropic-copyright-lawsuit-pirated-books-ai</a><br>
<br style="font-weight: bold;">
<span style="font-weight: bold;">Use of AI in evidence generation: NICE position statement</span><br>
This statement relates to the potential use of AI in the generation and
reporting of evidence considered by NICE; it does not consider the
evaluation of health technologies that use AI methods to perform their
function (AI-enabled technologies)<br>
<a href="https://www.nice.org.uk/about/what-we-do/our-research-work/use-of-ai-in-evidence-generation--nice-position-statement" target="_blank">https://www.nice.org.uk/about/what-we-do/our-research-work/use-of-ai-in-evidence-generation--nice-position-statement</a><br>
<br>
<span style="font-weight: bold;">Preparing the NHS for the AI Era: A Digital Health Record for Every Citizen (Tony Blair Institute for Global Change)</span><br>
<a href="https://www.institute.global/insights/public-services/preparing-the-nhs-for-the-ai-era-a-digital-health-record-for-every-citizen" target="_blank">https://www.institute.global/insights/public-services/preparing-the-nhs-for-the-ai-era-a-digital-health-record-for-every-citizen</a><br>
<br>
<span style="font-weight: bold;">Large Language Models forecast Patient Health Trajectories enabling Digital Twins (Preprint)</span><br>
The authors (affiliated with F. Hoffmann-La Roche and AstraZeneca)
developed the Digital Twin - Generative Pretrained Transformer (DT-GPT)
model, which utilises biomedical LLMs using rich electronic health
record data. DT-GPT demonstrates that LLMs can serve as a robust
medical forecasting platform, empowering digital twins which virtually
replicate patient characteristics beyond their training data. It is
envisioned that LLM-based digital twins will enable a variety of use
cases, including clinical trial simulations, treatment selection and
adverse event mitigation<br>
<a href="https://doi.org/10.1101/2024.07.05.24309957" target="_blank">https://doi.org/10.1101/2024.07.05.24309957</a><br>
<br>
<span style="font-weight: bold;">Detecting health and science misinformation with AI</span><br>
MISSCI is a theoretical model created in collaboration between IBM
Research, TU-Darmstadt, and MBZUAI. It aims to reconstruct the
reasoning process of false scientific claims that are based on actual
science &#8212; a common trick that makes misinformation hard to catch. The
approach uses a large language model (LLM)<br>
<a href="https://research.ibm.com/blog/detecting-health-science-misinformation-ai" target="_blank">https://research.ibm.com/blog/detecting-health-science-misinformation-ai</a><br>
<br>
<span style="font-weight: bold;">A new &#8216;AI scientist&#8217; can write science papers without any human input. Here&#8217;s why that&#8217;s a problem</span><br>
<a href="https://theconversation.com/a-new-ai-scientist-can-write-science-papers-without-any-human-input-heres-why-thats-a-problem-237029" target="_blank">https://theconversation.com/a-new-ai-scientist-can-write-science-papers-without-any-human-input-heres-why-thats-a-problem-237029</a><br>
<br>
<span style="font-weight: bold;">What AI Can Do in Healthcare&#8212;and What It Should Never Do</span><br>
Kaiser Permanente AI chief Daniel Yang is on the front line of
deploying artificial intelligence as well as testing its bounds; &#8216;We
did identify some hallucinations&#8217;<br>
<a href="https://www.wsj.com/tech/ai/what-ai-can-do-in-healthcareand-what-it-should-never-do-3e28a2b4" target="_blank">https://www.wsj.com/tech/ai/what-ai-can-do-in-healthcareand-what-it-should-never-do-3e28a2b4</a><br>
<br>
<span style="font-weight: bold;">The hidden reason AI costs are soaring&#8212;and it&#8217;s not because Nvidia chips are more expensive</span><br>
Building today&#8217;s massive AI models can cost hundreds of millions of
dollars, with projections suggesting it could hit a staggering billion
dollars within a few years. Much of that expense is for computing power
from specialized chips&#8212;typically Nvidia GPUs, of which tens of
thousands may be required, costing as much as $30,000 each. But
companies training AI models, or fine-tuning existing models to improve
performance on specific tasks, also struggle with another often
overlooked and rising cost: data labelling<br>
<a href="https://fortune.com/2024/08/23/data-labeling-ai-scaleai-snorkel-costs" target="_blank">https://fortune.com/2024/08/23/data-labeling-ai-scaleai-snorkel-costs</a>/<br>
<br>
<span style="font-weight: bold;">Access price decay of AI models </span><br>
Today, GPT-4o mini API access costs $0.15 per million tokens. When
ChatGPT launched, API access to the first available model - the far
less powerful GPT-3.5 - was $20 per million tokens. A drop of more than
100x in less than two years<br>
<a href="https://www.linkedin.com/posts/salathe_the-price-decay-of-ai-models-is-simply-mind-boggling-activity-7232625105946759168-Gp61" target="_blank">https://www.linkedin.com/posts/salathe_the-price-decay-of-ai-models-is-simply-mind-boggling-activity-7232625105946759168-Gp61 </a><br>
<br>
<span style="font-weight: bold;">AI cheating is overwhelming the education system &#8211; but teachers shouldn&#8217;t despair</span><br>
<a href="https://www.theguardian.com/commentisfree/article/2024/aug/24/ai-cheating-chat-gpt-openai-writing-essays-school-university" target="_blank">https://www.theguardian.com/commentisfree/article/2024/aug/24/ai-cheating-chat-gpt-openai-writing-essays-school-university</a><br>
<br>
This 'prompt engineering for LLMs' course, developed a little over a
year ago, was taught two times then stopped, because the technology was
developing (changing) so fast and they simply couldn't keep up with it
with a formal course. They also stopped because it was very clear that
students were developing AI skills on their own and didn't need a
course to teach them<br>
<a href="https://www.linkedin.com/posts/mboulos_ai-education-llm-activity-7227257756984979458-16Lx/" target="_blank">https://www.linkedin.com/posts/mboulos_ai-education-llm-activity-7227257756984979458-16Lx/</a><br>
<br style="font-weight: bold;">
<span style="font-weight: bold;">Does (chronological) order of results of a haemoglobin matter to an LLM?</span><br>
(Yes, and it shouldn't - unlike a human clinician, LLMs can be
unpredictable in their response to slight input variations of exactly
the same facts)<br>
<a href="https://www.linkedin.com/posts/maloykr_does-order-of-results-of-a-hemoglobin-matter-activity-7231061719299579906-3_fF/" target="_blank">https://www.linkedin.com/posts/maloykr_does-order-of-results-of-a-hemoglobin-matter-activity-7231061719299579906-3_fF/</a><br>
<br style="font-weight: bold;">
<span style="font-weight: bold;">Viewpoint: When you read the research
literature on certain themes, e.g., large language models in medicine,
it can feel (inconsistent) like playing a game of snakes and ladders</span><br>
Rather than a steady linear progress you soar up a level on a ladder or crash to earth, via a snake<br>
<a href="https://www.linkedin.com/posts/stephen-gilbert-31ba2587_when-you-read-the-research-literature-on-activity-7232673046061289472-UFCT/" target="_blank">https://www.linkedin.com/posts/stephen-gilbert-31ba2587_when-you-read-the-research-literature-on-activity-7232673046061289472-UFCT/</a><br>
<h2><a name="Sep24"></a>September 2024</h2>
<span style="font-weight: bold;">JAMIA's September 2024 issue is devoted to large language models in medicine</span><br>
<a href="https://academic.oup.com/jamia/issue/31/9" target="_blank">https://academic.oup.com/jamia/issue/31/9</a><br>

</body></html>